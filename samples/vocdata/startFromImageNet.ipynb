{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-----------------------------------------------------------------------------------------\n",
    "Usage: import the module (see Jupyter notebooks for examples), or run from\n",
    "       the command line as such:\n",
    "    # Train a model from coco weights.\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=coco --year=2012\n",
    "    # Train a new model starting from ImageNet weights.\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=imagenet --year=2012\n",
    "    # Continue training a model that you had trained earlier\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=/path/to/weights.h5  --year=2012\n",
    "    # Continue training the last model you trained\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=last\n",
    "    # Run VOC inference on the last model you trained\n",
    "    python3 voc.py inference --dataset=/path/to/VOCdevkit/ --model=last --year=2012 --limit=50\n",
    "------------------------------------------------------------------------------------------    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "# Inference result directory\n",
    "RESULTS_DIR = os.path.abspath(\"./inference/\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "# %matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "DEFAULT_LOGS_DIR =  MODEL_DIR\n",
    "DEFAULT_DATASET_YEAR = ''\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC DATASET MASK MAP FUNCTION\n",
    "# Following codes are mapping each mask color(SegmentationClass) to ground truth index.\n",
    "# - reference: https://d2l.ai/chapter_computer-vision/semantic-segmentation-and-dataset.html\n",
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'potted plant', 'sheep', 'sofa', 'train', 'tvmonitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_colormap2label():\n",
    "    \"\"\"Build a RGB color to label mapping for segmentation.\"\"\"\n",
    "    colormap2label = np.zeros(256 ** 3)\n",
    "    for i, colormap in enumerate(VOC_COLORMAP):\n",
    "        colormap2label[(colormap[0]*256 + colormap[1])*256 + colormap[2]] = i\n",
    "    return colormap2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_label_indices(colormap, colormap2label):\n",
    "    \"\"\"Map a RGB color to a label.\"\"\"\n",
    "    colormap = colormap.astype('int32')\n",
    "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n",
    "           + colormap[:, :, 2])\n",
    "    return colormap2label[idx]\n",
    "# VOC DATASET MASK MAP FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocConfig(Config):\n",
    "    NAME = \"voc\"\n",
    "\n",
    "    IMAGE_PER_GPU = 2\n",
    "\n",
    "    NUM_CLASSES = 1 + 20 # VOC 2012 have 20 classes. \"1\" is for background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(VocConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voc = COCO(\"pascal_train.json\") # load training annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocDataset(utils.Dataset):\n",
    "    def load_voc(self, dataset_dir, subset, year=DEFAULT_DATASET_YEAR, class_ids=None,\n",
    "              class_map=None, return_coco=False, auto_download=False):\n",
    "        \"\"\"Load a subset of the COCO dataset.\n",
    "        dataset_dir: The root directory of the COCO dataset.\n",
    "        subset: What to load (train, val, minival, valminusminival)\n",
    "        year: What dataset year to load (2014, 2017) as a string, not an integer\n",
    "        class_ids: If provided, only loads images that have the given classes.\n",
    "        class_map: TODO: Not implemented yet. Supports maping classes from\n",
    "            different datasets to the same class ID.\n",
    "        return_coco: If True, returns the COCO object.\n",
    "        auto_download: Automatically download and unzip MS-COCO images and annotations\n",
    "        \"\"\"\n",
    "\n",
    "        coco = COCO(\"pascal_train.json\")\n",
    "        if subset == \"minival\" or subset == \"valminusminival\":\n",
    "            subset = \"val\"\n",
    "        image_dir = \"{}/{}{}\".format(dataset_dir, subset, year)\n",
    "\n",
    "        # Load all classes or a subset?\n",
    "        if not class_ids:\n",
    "            # All classes\n",
    "            class_ids = sorted(coco.getCatIds())\n",
    "\n",
    "        # All images or a subset?\n",
    "        if class_ids:\n",
    "            image_ids = []\n",
    "            for id in class_ids:\n",
    "                image_ids.extend(list(coco.getImgIds(catIds=[id])))\n",
    "            # Remove duplicates\n",
    "            image_ids = list(set(image_ids))\n",
    "        else:\n",
    "            # All images\n",
    "            image_ids = list(coco.imgs.keys())\n",
    "\n",
    "        # Add classes\n",
    "        for i in class_ids:\n",
    "            self.add_class(\"coco\", i, coco.loadCats(i)[0][\"name\"])\n",
    "\n",
    "        # Add images\n",
    "        for i in image_ids:\n",
    "            self.add_image(\n",
    "                \"coco\", image_id=i,\n",
    "                path=os.path.join(image_dir, coco.imgs[i]['file_name']),\n",
    "                width=coco.imgs[i][\"width\"],\n",
    "                height=coco.imgs[i][\"height\"],\n",
    "                annotations=coco.loadAnns(coco.getAnnIds(\n",
    "                    imgIds=[i], catIds=class_ids, iscrowd=None)))\n",
    "        if return_coco:\n",
    "            return coco\n",
    "    \n",
    "    def load_raw_mask(self, image_id, class_or_object):\n",
    "            '''load two kinds of mask of VOC dataset.\n",
    "            image_id: id of mask\n",
    "            class_or_object: 'class_mask' or 'object_mask' for SegmentationClass or SegmentationObject\n",
    "            Returns:\n",
    "            image: numpy of mask image.\n",
    "            '''\n",
    "            assert class_or_object in ['class_mask', 'object_mask']\n",
    "            image = skimage.io.imread(self.image_info[image_id][class_or_object+'_path'])\n",
    "            if image.ndim != 3:\n",
    "                image = skimage.color.gray2rgb(image)\n",
    "            # If has an alpha channel, remove it for consistency\n",
    "            if image.shape[-1] == 4:\n",
    "                image = image[..., :3]\n",
    "            return image\n",
    "\n",
    "    def load_class_label(self, image_id):\n",
    "        '''Mapping SegmentationClass image's color to indice of ground truth \n",
    "        image_id: id of mask\n",
    "        Return:\n",
    "        class_label: [height, width] matrix contains values form 0 to 20\n",
    "        '''\n",
    "        raw_mask = self.load_raw_mask(image_id, 'class_mask')\n",
    "        class_label = voc_label_indices(raw_mask, build_colormap2label())\n",
    "        return class_label\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        '''Mapping annotation images to real Masks(MRCNN needed)\n",
    "        image_id: id of mask\n",
    "        Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        '''\n",
    "        class_label = self.load_class_label(image_id)\n",
    "        instance_mask = self.load_raw_mask(image_id, 'object_mask')\n",
    "        max_indice = int(np.max(class_label))\n",
    "\n",
    "        instance_label = []\n",
    "        instance_class = []\n",
    "        for i in range(1, max_indice+1):\n",
    "            if not np.any(class_label==i):\n",
    "                continue\n",
    "            gt_indice = i\n",
    "            object_filter = class_label == i\n",
    "            object_filter = object_filter.astype(np.uint8)\n",
    "            object_filter = np.dstack((object_filter,object_filter,object_filter))\n",
    "            filtered = np.multiply(object_filter, instance_mask)\n",
    "            gray = cv2.cvtColor(filtered, cv2.COLOR_RGB2GRAY)\n",
    "            max_gray = np.max(gray)\n",
    "            for sub_index in range(1, max_gray+1):\n",
    "                if not np.any(gray==sub_index):\n",
    "                    continue\n",
    "                instance_filter = gray == sub_index\n",
    "                instance_label += [instance_filter]\n",
    "                instance_class += [gt_indice]\n",
    "        masks = np.asarray(instance_label).transpose((1,2,0))\n",
    "        classes_ids = np.asarray(instance_class)\n",
    "        return masks, classes_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Inference\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, dataset, limit):\n",
    "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
    "\n",
    "    # Create directory\n",
    "    if not os.path.exists(RESULTS_DIR):\n",
    "        os.makedirs(RESULTS_DIR)\n",
    "    time_dir = \"{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
    "    time_dir = os.path.join(RESULTS_DIR, time_dir)\n",
    "    os.makedirs(time_dir)\n",
    "\n",
    "    # Load over images\n",
    "    for image_id in dataset.image_ids[:limit]:\n",
    "        # Load image and run detection\n",
    "        image = dataset.load_image(image_id)\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        # Encode image to RLE. Returns a string of multiple lines\n",
    "        source_id = dataset.image_info[image_id][\"id\"]\n",
    "        # Save image with masks\n",
    "        if len(r['class_ids']) > 0:\n",
    "            print('[*] {}th image has {} instance(s).'.format(image_id, len(r['class_ids'])))\n",
    "            visualize.display_instances(\n",
    "                image, r['rois'], r['masks'], r['class_ids'],\n",
    "                dataset.class_names, r['scores'],\n",
    "                show_bbox=True, show_mask=True,\n",
    "                title=\"Predictions\")\n",
    "            plt.savefig(\"{}/{}\".format(time_dir, dataset.image_info[image_id][\"id\"]))\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.imshow(image)\n",
    "            plt.savefig(\"{}/noinstance_{}\".format(time_dir, dataset.image_info[image_id][\"id\"]))\n",
    "            print('[*] {}th image have no instance.'.format(image_id))\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset /path/to/voc/] [--year <year>]\n",
      "                             --model /path/to/weights.h5\n",
      "                             [--logs /path/to/logs/] [--limit <image count>]\n",
      "                             <command>\n",
      "ipykernel_launcher.py: error: the following arguments are required: --model\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iblis/venv/mask-rcnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3327: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    # Parse command line arguments\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Train Mask R-CNN on PASCAL VOC.')\n",
    "    parser.add_argument(\"command\",\n",
    "                        metavar=\"<command>\",\n",
    "                        help=\"'train' or 'inference' on PASCAL VOC\")\n",
    "    parser.add_argument('--dataset', required=False,\n",
    "                        metavar=\"/path/to/voc/\",\n",
    "                        help='Directory of the PASCAL VOC dataset')\n",
    "    parser.add_argument('--year', required=False,\n",
    "                        default=DEFAULT_DATASET_YEAR,\n",
    "                        metavar=\"<year>\",\n",
    "                        help='Year of the PASCAL VOC dataset (2007 or 2012) (default=2012)')\n",
    "    parser.add_argument('--model', required=True,\n",
    "                        metavar=\"/path/to/weights.h5\",\n",
    "                        help=\"Path to weights .h5 file or 'voc'\")\n",
    "    parser.add_argument('--logs', required=False,\n",
    "                        default=DEFAULT_LOGS_DIR,\n",
    "                        metavar=\"/path/to/logs/\",\n",
    "                        help='Logs and checkpoints directory (default=logs/)')\n",
    "    parser.add_argument('--limit', required=False,\n",
    "                        default=10,\n",
    "                        metavar=\"<image count>\",\n",
    "                        help='Images to use for evaluation (default=10)')\n",
    "    # TODO\n",
    "    '''\n",
    "    parser.add_argument('--download', required=False,\n",
    "                        default=False,\n",
    "                        metavar=\"<True|False>\",\n",
    "                        help='Automatically download and unzip PASCAL VOC files (default=False)',\n",
    "                        type=bool)\n",
    "    '''\n",
    "    args = parser.parse_args()\n",
    "    print(\"Command: \", args.command)\n",
    "    print(\"Model: \", args.model)\n",
    "    print(\"Dataset: \", args.dataset)\n",
    "    print(\"Year: \", args.year)\n",
    "    print(\"Logs: \", args.logs)\n",
    "    #print(\"Auto Download: \", args.download)\n",
    "\n",
    "\n",
    "    # Configurations\n",
    "    if args.command == \"train\":\n",
    "        config = VocConfig()\n",
    "    else:\n",
    "        config = InferenceConfig()\n",
    "    config.display()\n",
    "\n",
    "    # Create model\n",
    "    if args.command == \"train\":\n",
    "        model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "    else:\n",
    "        model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "\n",
    "\n",
    "    # Select weights file to load\n",
    "    if args.model.lower() == \"coco\":\n",
    "        model_path = COCO_WEIGHTS_PATH\n",
    "    elif args.model.lower() == \"last\":\n",
    "        # Find last trained weights\n",
    "        model_path = model.find_last()\n",
    "    elif args.model.lower() == \"imagenet\":\n",
    "        # Start from ImageNet trained weights\n",
    "        model_path = model.get_imagenet_weights()\n",
    "    else:\n",
    "        model_path = args.model\n",
    "\n",
    "    # Load weights\n",
    "    if args.model.lower() == \"coco\":\n",
    "        # Exclude the last layers because they require a matching\n",
    "        # number of classes\n",
    "        model.load_weights(model_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    else:\n",
    "        print(\"Loading weights \", model_path)\n",
    "        model.load_weights(model_path, by_name=True)\n",
    "\n",
    "\n",
    "    # Train or evaluate\n",
    "    if args.command == \"train\":\n",
    "        # Training dataset. Use the training set and 35K from the\n",
    "        # validation set, as as in the Mask RCNN paper.\n",
    "        dataset_train = VocDataset()\n",
    "        dataset_train.load_voc(args.dataset, \"train\", year=args.year)\n",
    "        dataset_train.prepare()\n",
    "\n",
    "        # Validation dataset\n",
    "        dataset_val = VocDataset()\n",
    "        dataset_val.load_voc(args.dataset, \"val\", year=args.year)\n",
    "        dataset_val.prepare()\n",
    "\n",
    "        # Image Augmentation\n",
    "        # Right/Left flip 50% of the time\n",
    "        augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "        # *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "        # Training - Stage 1\n",
    "        print(\"Training network heads\")\n",
    "        model.train(dataset_train, dataset_val,\n",
    "                    learning_rate=config.LEARNING_RATE,\n",
    "                    epochs=40,\n",
    "                    layers='heads',\n",
    "                    augmentation=augmentation)\n",
    "\n",
    "        # Training - Stage 2\n",
    "        # Finetune layers from ResNet stage 4 and up\n",
    "        print(\"Fine tune Resnet stage 4 and up\")\n",
    "        model.train(dataset_train, dataset_val,\n",
    "                    learning_rate=config.LEARNING_RATE,\n",
    "                    epochs=120,\n",
    "                    layers='4+',\n",
    "                    augmentation=augmentation)\n",
    "\n",
    "        # Training - Stage 3\n",
    "        # Fine tune all layers\n",
    "        print(\"Fine tune all layers\")\n",
    "        model.train(dataset_train, dataset_val,\n",
    "                    learning_rate=config.LEARNING_RATE / 10,\n",
    "                    epochs=160,\n",
    "                    layers='all',\n",
    "                    augmentation=augmentation)\n",
    "\n",
    "    elif args.command == \"inference\":\n",
    "        #print(\"evaluate have not been implemented\")\n",
    "        # Validation dataset\n",
    "        dataset_val = VocDataset()\n",
    "        voc = dataset_val.load_voc(args.dataset, \"val\", year=args.year)\n",
    "        dataset_val.prepare()\n",
    "        print(\"Running voc inference on {} images.\".format(args.limit))\n",
    "        inference(model, dataset_val, int(args.limit))\n",
    "    else:\n",
    "        print(\"'{}' is not recognized. \"\n",
    "              \"Use 'train' or 'inference'\".format(args.command))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
