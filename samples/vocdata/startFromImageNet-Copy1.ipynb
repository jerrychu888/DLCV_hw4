{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-----------------------------------------------------------------------------------------\n",
    "Usage: import the module (see Jupyter notebooks for examples), or run from\n",
    "       the command line as such:\n",
    "    # Train a model from coco weights.\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=coco --year=2012\n",
    "    # Train a new model starting from ImageNet weights.\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=imagenet --year=2012\n",
    "    # Continue training a model that you had trained earlier\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=/path/to/weights.h5  --year=2012\n",
    "    # Continue training the last model you trained\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=last\n",
    "    # Run VOC inference on the last model you trained\n",
    "    python3 voc.py inference --dataset=/path/to/VOCdevkit/ --model=last --year=2012 --limit=50\n",
    "------------------------------------------------------------------------------------------    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "# Inference result directory\n",
    "RESULTS_DIR = os.path.abspath(\"./inference/\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn import visualize\n",
    "\n",
    "import matplotlib\n",
    "# Agg backend runs without a display\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "DEFAULT_DATASET_YEAR = ''\n",
    "\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC DATASET MASK MAP FUNCTION\n",
    "# Following codes are mapping each mask color(SegmentationClass) to ground truth index.\n",
    "# - reference: https://d2l.ai/chapter_computer-vision/semantic-segmentation-and-dataset.html\n",
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'potted plant', 'sheep', 'sofa', 'train', 'tvmonitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_colormap2label():\n",
    "    \"\"\"Build a RGB color to label mapping for segmentation.\"\"\"\n",
    "    colormap2label = np.zeros(256 ** 3)\n",
    "    for i, colormap in enumerate(VOC_COLORMAP):\n",
    "        colormap2label[(colormap[0]*256 + colormap[1])*256 + colormap[2]] = i\n",
    "    return colormap2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_label_indices(colormap, colormap2label):\n",
    "    \"\"\"Map a RGB color to a label.\"\"\"\n",
    "    colormap = colormap.astype('int32')\n",
    "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n",
    "           + colormap[:, :, 2])\n",
    "    return colormap2label[idx]\n",
    "# VOC DATASET MASK MAP FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocConfig(Config):\n",
    "    NAME = \"voc\"\n",
    "\n",
    "    IMAGE_PER_GPU = 2\n",
    "\n",
    "    NUM_CLASSES = 1 + 20 # VOC 2012 have 20 classes. \"1\" is for background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(VocConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = COCO(\"pascal_train.json\") # load training annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocDataset(utils.Dataset):\n",
    "    def load_voc(self, dataset_dir, trainval, year=''):\n",
    "        \"\"\"Load a voc_year of the VOC dataset.\n",
    "        dataset_dir: The root directory of the VOC dataset, example: '/samples/vocdata/'\n",
    "        trainval: 'train' or 'val' for Training or Validation\n",
    "        year: all as empty string ''\n",
    "        \"\"\"\n",
    "\n",
    "        voc_year = year\n",
    "        Segmentation = os.path.join(dataset_dir, voc_year, 'ImageSets', 'Segmentation')\n",
    "        JPEGImages = os.path.join(dataset_dir, voc_year, 'JPEGImages')\n",
    "        Annotations = os.path.join(dataset_dir, voc_year, 'Annotations')\n",
    "        SegmentationClass = os.path.join(dataset_dir, voc_year, 'SegmentationClass')\n",
    "        SegmentationObject = os.path.join(dataset_dir, voc_year, 'SegmentationObject')\n",
    "\n",
    "        # load classes of VOC, BG is initialed in parent class.\n",
    "        for idx, class_name in enumerate(VOC_CLASSES[1:]):\n",
    "            self.add_class(\"voc\", idx + 1, class_name)\n",
    "\n",
    "        assert trainval in ['train', 'val']\n",
    "        # read segmentation annotation file\n",
    "        annotation_file = os.path.join(Segmentation, trainval + '.txt')\n",
    "        image_ids = []\n",
    "        with open(annotation_file) as f:\n",
    "            image_id_list = [line.strip() for line in f]\n",
    "            image_ids += image_id_list\n",
    "\n",
    "        for image_id in image_ids:\n",
    "            image_file_name = '{}.jpg'.format(image_id)\n",
    "            mask_file_name = '{}.png'.format(image_id)\n",
    "            xml_file_name = '{}.xml'.format(image_id)\n",
    "            image_path = os.path.join(JPEGImages, image_file_name)\n",
    "\n",
    "            # Parse Annotations XML File\n",
    "            with open(os.path.join(Annotations, xml_file_name)) as f:\n",
    "                soup = bs(f, 'xml')\n",
    "            objects = soup.find_all('object')\n",
    "            image_contains_class_flag = False\n",
    "            for obj in objects:\n",
    "                class_name = obj.find('name').text\n",
    "                if class_name in VOC_CLASSES:\n",
    "                    image_contains_class_flag = True\n",
    "                    continue\n",
    "            if image_contains_class_flag:\n",
    "                class_mask_path = os.path.join(SegmentationClass, mask_file_name)\n",
    "                object_mask_path = os.path.join(SegmentationObject, mask_file_name)\n",
    "                self.add_image(\"voc\",\n",
    "                                image_id=image_file_name,\n",
    "                                path=image_path,\n",
    "                                class_mask_path=class_mask_path,\n",
    "                                object_mask_path=object_mask_path)\n",
    "    def load_raw_mask(self, image_id, class_or_object):\n",
    "            '''load two kinds of mask of VOC dataset.\n",
    "            image_id: id of mask\n",
    "            class_or_object: 'class_mask' or 'object_mask' for SegmentationClass or SegmentationObject\n",
    "            Returns:\n",
    "            image: numpy of mask image.\n",
    "            '''\n",
    "            assert class_or_object in ['class_mask', 'object_mask']\n",
    "            image = skimage.io.imread(self.image_info[image_id][class_or_object+'_path'])\n",
    "            if image.ndim != 3:\n",
    "                image = skimage.color.gray2rgb(image)\n",
    "            # If has an alpha channel, remove it for consistency\n",
    "            if image.shape[-1] == 4:\n",
    "                image = image[..., :3]\n",
    "            return image\n",
    "\n",
    "        def load_class_label(self, image_id):\n",
    "            '''Mapping SegmentationClass image's color to indice of ground truth \n",
    "            image_id: id of mask\n",
    "            Return:\n",
    "            class_label: [height, width] matrix contains values form 0 to 20\n",
    "            '''\n",
    "            raw_mask = self.load_raw_mask(image_id, 'class_mask')\n",
    "            class_label = voc_label_indices(raw_mask, build_colormap2label())\n",
    "            return class_label\n",
    "\n",
    "        def load_mask(self, image_id):\n",
    "            '''Mapping annotation images to real Masks(MRCNN needed)\n",
    "            image_id: id of mask\n",
    "            Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                one mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "            '''\n",
    "            class_label = self.load_class_label(image_id)\n",
    "            instance_mask = self.load_raw_mask(image_id, 'object_mask')\n",
    "            max_indice = int(np.max(class_label))\n",
    "\n",
    "            instance_label = []\n",
    "            instance_class = []\n",
    "            for i in range(1, max_indice+1):\n",
    "                if not np.any(class_label==i):\n",
    "                    continue\n",
    "                gt_indice = i\n",
    "                object_filter = class_label == i\n",
    "                object_filter = object_filter.astype(np.uint8)\n",
    "                object_filter = np.dstack((object_filter,object_filter,object_filter))\n",
    "                filtered = np.multiply(object_filter, instance_mask)\n",
    "                gray = cv2.cvtColor(filtered, cv2.COLOR_RGB2GRAY)\n",
    "                max_gray = np.max(gray)\n",
    "                for sub_index in range(1, max_gray+1):\n",
    "                    if not np.any(gray==sub_index):\n",
    "                        continue\n",
    "                    instance_filter = gray == sub_index\n",
    "                    instance_label += [instance_filter]\n",
    "                    instance_class += [gt_indice]\n",
    "            masks = np.asarray(instance_label).transpose((1,2,0))\n",
    "            classes_ids = np.asarray(instance_class)\n",
    "            return masks, classes_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Inference\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, dataset, limit):\n",
    "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
    "\n",
    "    # Create directory\n",
    "    if not os.path.exists(RESULTS_DIR):\n",
    "        os.makedirs(RESULTS_DIR)\n",
    "    time_dir = \"{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
    "    time_dir = os.path.join(RESULTS_DIR, time_dir)\n",
    "    os.makedirs(time_dir)\n",
    "\n",
    "    # Load over images\n",
    "    for image_id in dataset.image_ids[:limit]:\n",
    "        # Load image and run detection\n",
    "        image = dataset.load_image(image_id)\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        # Encode image to RLE. Returns a string of multiple lines\n",
    "        source_id = dataset.image_info[image_id][\"id\"]\n",
    "        # Save image with masks\n",
    "        if len(r['class_ids']) > 0:\n",
    "            print('[*] {}th image has {} instance(s).'.format(image_id, len(r['class_ids'])))\n",
    "            visualize.display_instances(\n",
    "                image, r['rois'], r['masks'], r['class_ids'],\n",
    "                dataset.class_names, r['scores'],\n",
    "                show_bbox=True, show_mask=True,\n",
    "                title=\"Predictions\")\n",
    "            plt.savefig(\"{}/{}\".format(time_dir, dataset.image_info[image_id][\"id\"]))\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.imshow(image)\n",
    "            plt.savefig(\"{}/noinstance_{}\".format(time_dir, dataset.image_info[image_id][\"id\"]))\n",
    "            print('[*] {}th image have no instance.'.format(image_id))\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    # Parse command line arguments\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Train Mask R-CNN on PASCAL VOC.')\n",
    "    parser.add_argument(\"command\",\n",
    "                        metavar=\"<command>\",\n",
    "                        help=\"'train' or 'inference' on PASCAL VOC\")\n",
    "    parser.add_argument('--dataset', required=False,\n",
    "                        metavar=\"/path/to/voc/\",\n",
    "                        help='Directory of the PASCAL VOC dataset')\n",
    "    parser.add_argument('--year', required=False,\n",
    "                        default=DEFAULT_DATASET_YEAR,\n",
    "                        metavar=\"<year>\",\n",
    "                        help='Year of the PASCAL VOC dataset (2007 or 2012) (default=2012)')\n",
    "    parser.add_argument('--model', required=True,\n",
    "                        metavar=\"/path/to/weights.h5\",\n",
    "                        help=\"Path to weights .h5 file or 'voc'\")\n",
    "    parser.add_argument('--logs', required=False,\n",
    "                        default=DEFAULT_LOGS_DIR,\n",
    "                        metavar=\"/path/to/logs/\",\n",
    "                        help='Logs and checkpoints directory (default=logs/)')\n",
    "    parser.add_argument('--limit', required=False,\n",
    "                        default=10,\n",
    "                        metavar=\"<image count>\",\n",
    "                        help='Images to use for evaluation (default=10)')\n",
    "    # TODO\n",
    "    '''\n",
    "    parser.add_argument('--download', required=False,\n",
    "                        default=False,\n",
    "                        metavar=\"<True|False>\",\n",
    "                        help='Automatically download and unzip PASCAL VOC files (default=False)',\n",
    "                        type=bool)\n",
    "    '''\n",
    "    args = parser.parse_args()\n",
    "    print(\"Command: \", args.command)\n",
    "    print(\"Model: \", args.model)\n",
    "    print(\"Dataset: \", args.dataset)\n",
    "    print(\"Year: \", args.year)\n",
    "    print(\"Logs: \", args.logs)\n",
    "    #print(\"Auto Download: \", args.download)\n",
    "\n",
    "\n",
    "    # Configurations\n",
    "    if args.command == \"train\":\n",
    "        config = VocConfig()\n",
    "    else:\n",
    "        config = InferenceConfig()\n",
    "    config.display()\n",
    "\n",
    "    # Create model\n",
    "    if args.command == \"train\":\n",
    "        model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "    else:\n",
    "        model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "\n",
    "\n",
    "    # Select weights file to load\n",
    "    if args.model.lower() == \"coco\":\n",
    "        model_path = COCO_WEIGHTS_PATH\n",
    "    elif args.model.lower() == \"last\":\n",
    "        # Find last trained weights\n",
    "        model_path = model.find_last()\n",
    "    elif args.model.lower() == \"imagenet\":\n",
    "        # Start from ImageNet trained weights\n",
    "        model_path = model.get_imagenet_weights()\n",
    "    else:\n",
    "        model_path = args.model\n",
    "\n",
    "    # Load weights\n",
    "    if args.model.lower() == \"coco\":\n",
    "        # Exclude the last layers because they require a matching\n",
    "        # number of classes\n",
    "        model.load_weights(model_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    else:\n",
    "        print(\"Loading weights \", model_path)\n",
    "        model.load_weights(model_path, by_name=True)\n",
    "\n",
    "\n",
    "    # Train or evaluate\n",
    "    if args.command == \"train\":\n",
    "        # Training dataset. Use the training set and 35K from the\n",
    "        # validation set, as as in the Mask RCNN paper.\n",
    "        dataset_train = VocDataset()\n",
    "        dataset_train.load_voc(args.dataset, \"train\", year=args.year)\n",
    "        dataset_train.prepare()\n",
    "\n",
    "        # Validation dataset\n",
    "        dataset_val = VocDataset()\n",
    "        dataset_val.load_voc(args.dataset, \"val\", year=args.year)\n",
    "        dataset_val.prepare()\n",
    "\n",
    "        # Image Augmentation\n",
    "        # Right/Left flip 50% of the time\n",
    "        augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "        # *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "        # Training - Stage 1\n",
    "        print(\"Training network heads\")\n",
    "        model.train(dataset_train, dataset_val,\n",
    "                    learning_rate=config.LEARNING_RATE,\n",
    "                    epochs=40,\n",
    "                    layers='heads',\n",
    "                    augmentation=augmentation)\n",
    "\n",
    "        # Training - Stage 2\n",
    "        # Finetune layers from ResNet stage 4 and up\n",
    "        print(\"Fine tune Resnet stage 4 and up\")\n",
    "        model.train(dataset_train, dataset_val,\n",
    "                    learning_rate=config.LEARNING_RATE,\n",
    "                    epochs=120,\n",
    "                    layers='4+',\n",
    "                    augmentation=augmentation)\n",
    "\n",
    "        # Training - Stage 3\n",
    "        # Fine tune all layers\n",
    "        print(\"Fine tune all layers\")\n",
    "        model.train(dataset_train, dataset_val,\n",
    "                    learning_rate=config.LEARNING_RATE / 10,\n",
    "                    epochs=160,\n",
    "                    layers='all',\n",
    "                    augmentation=augmentation)\n",
    "\n",
    "    elif args.command == \"inference\":\n",
    "        #print(\"evaluate have not been implemented\")\n",
    "        # Validation dataset\n",
    "        dataset_val = VocDataset()\n",
    "        voc = dataset_val.load_voc(args.dataset, \"val\", year=args.year)\n",
    "        dataset_val.prepare()\n",
    "        print(\"Running voc inference on {} images.\".format(args.limit))\n",
    "        inference(model, dataset_val, int(args.limit))\n",
    "    else:\n",
    "        print(\"'{}' is not recognized. \"\n",
    "              \"Use 'train' or 'inference'\".format(args.command))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
